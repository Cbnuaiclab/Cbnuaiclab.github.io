<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CHHUN Rotanakkosal - AICLab</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="../assets/css/profile.css">
</head>
<body>
    <header>
        <nav>
            <div class="logo"><span></span></div>
            <button class="mobile-menu-toggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-menu">
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#team">Team</a></li>
                <li><a href="../index.html#publications">Publications</a></li>
                <li><a href="../index.html#projects">Research Projects</a></li>
                <li><a href="../index.html#activities">Member's Activities</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </nav>
    </header>

    <div class="profile-container">
        <div class="profile-header">
            <div class="profile-photo">
                <img src="../assets/img/profile/chhun_rotanakkosal.jpg"/>
            </div>
            <h1>CHHUN Rotanakkosal</h1>
            <div class="position">Integrated Student (Master's)</div>
            <div class="expertise">Computer Vision | LLM | Full-Stack Development | DevOps</div>
            <div style="margin-top: 1rem; display: flex; gap: 1rem; flex-wrap: wrap; justify-content: center;">
                <a href="https://kh.linkedin.com/in/chhun-rotanakkosal-717a6222b" target="_blank"
                   style="display: inline-flex; align-items: center; gap: 0.5rem; color: var(--accent-red); text-decoration: none; font-weight: 600; border: 2px solid var(--accent-red); padding: 0.5rem 1rem; border-radius: 8px; transition: all 0.3s;"
                   onmouseover="this.style.background='var(--accent-red)'; this.style.color='white';"
                   onmouseout="this.style.background=''; this.style.color='var(--accent-red)';">
                    <i class="fab fa-linkedin"></i>
                    LinkedIn Profile
                </a>
            </div>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-user-graduate"></i> Academic Background</h2>
            <ul>
                <li><strong>Current:</strong> Master's Degree in Big Data (Integrated Student), Chungbuk National University (September 2024 - Present)</li>
                <li><strong>Bachelor's Degree:</strong> Computer Science, Royal University of Phnom Penh, Cambodia (2023)</li>
            </ul>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-briefcase"></i> Professional Experience</h2>
            <ul>
                <li><strong>2023 - Mid 2025:</strong> IT Instructor, Korean Software HRD Center, Phnom Penh, Cambodia</li>
                <li>Taught software development and DevOps practices</li>
                <li><strong>Current:</strong> Researcher at AI Convergence Lab, Chungbuk National University</li>
            </ul>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-microscope"></i> Research Focus</h2>
            <div class="highlight">
                <p>His work centers on the intersection of computer vision and Large Language Models (LLMs). He is particularly passionate about the synergy between computer vision and LLMs, exploring how these technologies can be integrated to create intelligent systems.</p>
            </div>
            <ul>
                <li><strong>Computer Vision & LLM Integration:</strong> Exploring synergies between visual understanding and language models</li>
                <li><strong>Multimodal AI Solutions:</strong> Developing systems that leverage both visual and textual data</li>
                <li><strong>Intelligent Systems:</strong> Creating AI systems that can understand and process multiple data modalities</li>
                <li><strong>Robotic Vision:</strong> Developing perception systems for autonomous robotic manipulation</li>
            </ul>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-file-alt"></i> Publications</h2>
            <div class="publication-item" style="margin-bottom: 1.5rem; padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                <h4 style="color: var(--accent-red); margin-bottom: 0.5rem;">The Role of Continuous Integration and Continuous Deployment in Modern DevOps Practices</h4>
                <p style="margin-bottom: 0.5rem; color: #555;"><strong>Authors:</strong> Rotanakkosal Chhun, Vungsovanreach Kong, Sokheang Chan, Naro Vorn, Tae-Kyung Kim</p>
                <p style="color: #666;">
                    <strong>Conference:</strong> FITAT 2025 - 17th International Conference on Frontiers of Information Technology, Applications and Tools -
                    <a href="https://fitat.org/" target="_blank" style="color: var(--accent-red); text-decoration: none; border-bottom: 2px solid var(--accent-red);" onmouseover="this.style.borderColor='var(--accent-gold)'" onmouseout="this.style.borderColor='var(--accent-red)'">View Conference</a>
                </p>
            </div>
            <div class="publication-item" style="padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                <h4 style="color: var(--accent-red); margin-bottom: 0.5rem;">Enhancing RAG Ranking with Leave-One-Out Reward Supervision and Direct Preference Optimization</h4>
                <p style="margin-bottom: 0.5rem; color: #555;"><strong>Authors:</strong> Rotanakkosal Chhun, Sokheang Chan, Vungsovanreach Kong, Tae-Kyung Kim</p>
                <p style="color: #666;">
                    <strong>Conference:</strong> BIGDAS Conference 2024 -
                    <a href="https://bigdas.or.kr" target="_blank" style="color: var(--accent-red); text-decoration: none; border-bottom: 2px solid var(--accent-red);" onmouseover="this.style.borderColor='var(--accent-gold)'" onmouseout="this.style.borderColor='var(--accent-red)'">View Conference</a>
                </p>
            </div>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-project-diagram"></i> Research Projects</h2>
            <div class="publication-item" style="padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                <h3 style="color: var(--accent-red); margin-bottom: 1rem;">
                    <a href="../projects.html" style="color: var(--accent-red); text-decoration: none; border-bottom: 2px solid var(--accent-red);"
                       onmouseover="this.style.borderColor='var(--accent-gold)'"
                       onmouseout="this.style.borderColor='var(--accent-red)'">
                        Arm Robot for Bin-Picking in Unstructured Environments
                    </a>
                </h3>
                <p style="margin-bottom: 1rem; color: #555;">
                    Development of an autonomous arm picking robot designed to detect, localize, and grasp objects in cluttered,
                    unstructured environments. The project addresses critical challenges in robotic perception, particularly for
                    transparent and reflective objects under heavy occlusion conditions.
                </p>
                <h4 style="color: var(--accent-red); margin-top: 1.5rem; margin-bottom: 0.75rem;">Key Contributions:</h4>
                <ul style="margin-left: 1.5rem;">
                    <li><strong>Instance Segmentation Pipeline:</strong> Implemented and benchmarked advanced segmentation models including SAM 2 and UOAIS to solve transparency and heavy occlusion challenges. Achieved real-time performance with UOAIS (15 fps) while maintaining accuracy, and tested Mask2Former for enhanced robustness in complex scenarios</li>
                    <li><strong>Hardware Integration:</strong> Engineered complete integration of Intel RealSense L515 LiDAR camera with the instance segmentation pipeline using a custom Python-SDK wrapper, enabling seamless real-time depth and RGB data acquisition</li>
                    <li><strong>3D Point Cloud Conversion:</strong> Developed robust algorithms to convert 2D pixel coordinates and depth data into accurate 3D point cloud coordinates (x, y, z), providing essential spatial information for robotic grasping operations</li>
                    <li><strong>Grasp Detection Research:</strong> Conducted comprehensive study on Contact-GraspNet approach for 6-DoF (6 Degrees of Freedom) grasp detection, advancing understanding of grasp pose estimation in cluttered environments</li>
                </ul>
                <p style="margin-top: 1rem; font-size: 0.9rem; color: #555;">
                    <strong style="color: var(--accent-red);">Technologies:</strong> SAM 2, UOAIS, Mask2Former, Intel RealSense L515, Contact-GraspNet, Python, 3D Point Cloud Processing, Real-time Computer Vision
                </p>
            </div>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-lightbulb"></i> Technical Expertise</h2>
            <div class="highlight">
                <p>With a strong foundation in software engineering and emerging expertise in AI research, his technical skills span multiple domains from traditional software development to cutting-edge AI technologies.</p>
            </div>
            <ul>
                <li><strong>Full-Stack Development:</strong> Proficient across multiple programming languages and frameworks</li>
                <li><strong>DevOps:</strong> Cloud platforms and deployment practices</li>
                <li><strong>Computer Vision:</strong> Image processing and visual understanding systems</li>
                <li><strong>Large Language Models:</strong> Integration and application of LLMs</li>
                <li><strong>Programming Languages:</strong> Multiple languages across different paradigms</li>
            </ul>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-bullseye"></i> Career Aspirations</h2>
            <p>Aims to pursue doctoral studies to further advance contributions to the field of artificial intelligence and its practical applications. His goal is to bridge the gap between theoretical AI research and real-world implementations, creating systems that are both academically rigorous and practically valuable.</p>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-star"></i> Teaching Experience</h2>
            <p>As an IT Instructor at the Korean Software HRD Center (2023-2025), he gained valuable experience in teaching software development and DevOps practices. This teaching background provides him with the ability to communicate complex technical concepts clearly and mentor junior developers and students.</p>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-rocket"></i> Current Research at AICLab</h2>
            <ul>
                <li>Developing multimodal AI solutions combining vision and language</li>
                <li>Exploring practical applications of computer vision and LLM integration</li>
                <li>Contributing to lab projects at the intersection of visual AI and language understanding</li>
                <li>Bridging software engineering practices with AI research methodologies</li>
            </ul>
        </div>

        <div class="profile-section">
            <h2><i class="fas fa-comments"></i> Research Philosophy</h2>
            <p>Believes in creating AI systems that combine strong engineering foundations with innovative research. His approach integrates practical software development skills with cutting-edge AI research, ensuring that solutions are both technically sound and deployable in real-world scenarios.</p>
        </div>
    </div>

    <footer id="contact">
        <div class="footer-main">
            <div class="footer-content">
                <div class="footer-section footer-about">
                    <div class="container">
                        <img src="../assets/img/logo/aiclab_logo_white.png" alt="AICLab Logo" class="footer-logo">
                    </div>
                    <div class="footer-text">
                        <h3>AI Convergence Lab</h3>
                        <p class="footer-tagline">Pioneering Applied AI and Computer Vision Research</p>
                        <p class="footer-description">
                            Bridging academic excellence with industry needs through innovative AI solutions and collaborative research.
                        </p>
                    </div>
                </div>

                <div class="footer-section footer-contact">
                    <h3>Contact Information</h3>
                    <div class="contact-item">
                        <i class="fas fa-envelope"></i>
                        <div>
                            <strong>Email</strong>
                            <a href="mailto:cbnuaiclab@gmail.com">cbnuaiclab@gmail.com</a>
                        </div>
                    </div>
                    <div class="contact-item">
                        <i class="fas fa-map-marker-alt"></i>
                        <div>
                            <strong>Location</strong>
                            <p>Room N13-216, Chungbuk National University<br>
                            Chungdae-Ro 1, Seowon-Gu<br>
                            Cheongju, Chungbuk, South Korea</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="footer-bottom">
            <div class="footer-bottom-content">
                <p>&copy; 2025 AICLab - AI Convergence Lab. All rights reserved.</p>
                <p class="footer-affiliation">Chungbuk National University</p>
            </div>
        </div>
    </footer>
    <script src="../assets/js/profile.js"></script>
</body>
</html>